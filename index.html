<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<link rel="stylesheet" type="text/css" href="style.css">
	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;1,200;1,300;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;1,100;1,300;1,400;1,500;1,700&family=Source+Code+Pro:wght@400;700&display=swap" rel="stylesheet">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Why Ai is Bias?</title>
</head>
<body>
	<header>
		<nav id="menu">
			<ul class="menu-fixed">
				<li class="logo">
					<a href="index.html">WHY AI IS BIAS?</a>
				</li>
				<li>
					<a href="book.html">Book</a>
				</li>
				<li>
					<a href="about.html">About</a>
				</li>
				<li>
					<a href="index.html" class="active">Archive</a>
				</li>
			</ul>
		</nav>
	</header>
	<article>
		<div id="title">
			<h1 class="title">.Why AI is Bias?</h1>
			<p class="legend">/Project that show bias in AI.</p>
		</div>
		<div class="content">
	</article>
	<main>
		<table>
			<tbody>
				<tr>
					<td href='#project1' class="reply">
            			<span class="cover">
            				<div class="popup-container-images-2">
                   				<span class="col1">07.1966</span>
                    			<span class="col2">The Summer Vision Project</span>
                			<div class="popup-detail-image-2">
                    			<img class="image-hover"src="imagens/summervision.jpeg">
               				 </div>
            				</div>
            			</span>
						<div class='target' style='display:none'>
							<div class="content-columns">
                    			<div class="col3">
                        			<img class="image"src="imagens/summervision.jpeg">
                        			<br>
                        			<span class="bodytext">In 1966, Marvin Minsky was a young professor at MIT, making a name for himself in the emerging field of artificial intelligence. </span>
                        			<br>
                        			<br>
                        			<span><a class="link" href="https://towardsdatascience.com/overcoming-imagenet-dataset-biases-with-pass-6e54c66e77a" target="_blank">Read More</a></span>
                    			</div>
								</div>
							</div>
						</div>
					</td>  
			    </tr>
				<tr>
					<td href='#project1' class="reply">
            			<span class="cover">
            				<div class="popup-container-images-2">
                   				<span class="col1">(-).2006</span>
                    			<span class="col2">ImageNet</span>
                			<div class="popup-detail-image-2">
                    			<img class="image-hover"src="imagens/imagenet.png">
               				 </div>
            				</div>
            			</span>
						<div class='target' style='display:none'>
							<div class="content-columns">
                    			<div class="col3">
                        			<img class="image"src="imagens/imagenet.png">
                        			<br>
                        			<span class="bodytext">ImageNet is one of the most widely used datasets in Computer Vision applications. However, studies have shown biases prevalent in this dataset based on the collection methodology and the types of images present. </span>
                        			<br>
                        			<br>
                        			<span><a class="link" href="https://towardsdatascience.com/overcoming-imagenet-dataset-biases-with-pass-6e54c66e77a" target="_blank">Read More</a></span>
                    			</div>
								</div>
							</div>
						</div>
					</td>  
			    </tr>
			   <tr>
					<td href='#project1' class="reply">
            			<span class="cover">
            				<div class="popup-container-images-2">
                   				<span class="col1">(-).2009</span>
                    			<span class="col2">ImageNet Roulette</span>
                			<div class="popup-detail-image-2">
                    			<img class="image-hover"src="imagens/imagenetroulette.png">
               				 </div>
            				</div>
            			</span>
						<div class='target' style='display:none'>
							<div class="content-columns">
                    			<div class="col3">
                        			<img class="image"src="imagens/imagenetroulette.png">
                        			<br>
                        			<span class="bodytext">ImageNet Roulette uses an open-source Caffe deep-learning framework (produced at UC Berkeley) trained on the images and labels in the “person” categories (which are currently “down for maintenance”). Proper nouns were removed.” </span>
                        			<br>
                        			<br>
                        			<span><a class="link" href="https://excavating.ai/" target="_blank">Read More</a></span>
                    			</div>
								</div>
							</div>
						</div>
					</td>  
			    </tr>
			    <tr>
					<td href='#project1' class="reply">
            			<span class="cover">
            				<div class="popup-container-images-2">
                   				<span class="col1">06.2016</span>
                    			<span class="col2">COMPAS Software</span>
                			<div class="popup-detail-image-2">
                    			<img class="image-hover"src="imagens/compas.png">
               				 </div>
            				</div>
            			</span>
						<div class='target' style='display:none'>
							<div class="content-columns">
                    			<div class="col3">
                        			<img class="image"src="imagens/compas.png">
                        			<br>
                        			<span class="bodytext">There’s software used across the country to predict future criminals. And it’s biased against blacks.
									“Fugett (left): LOW RISK3; Prior Offense; 1 attempted burglary; ; Subsequent Offenses; 3 drug possessions. 
									Parker (right): HIGH RISK10; Prior Offense: 1 resisting arrest without violence Subsequent Offenses: None. </span>
                        			<br>
                        			<br>
                        			<span><a class="link" href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" target="_blank">Read More</a></span>
                    			</div>
								</div>
							</div>
						</div>
					</td>  
			    </tr>
			    <tr>
					<td href='#project1' class="reply">
            			<span class="cover">
            				<div class="popup-container-images-2">
                   				<span class="col1">01.2017</span>
                    			<span class="col2">HyperFace</span>
                			<div class="popup-detail-image-2">
                    			<img class="image-hover"src="imagens/hyperfaces.png">
               				 </div>
            				</div>
            			</span>
						<div class='target' style='display:none'>
							<div class="content-columns">
                    			<div class="col3">
                        			<img class="image"src="imagens/hyperfaces.png">
                        			<br>
                        			<span class="bodytext">HyperFace that fools computer vision algorithms to see multiple human faces where there is none.”
									The neural glitches of HyperFace exploit such a cognitive gap and reveal what a human face looks like to a machine. This gap between human and machine perception helps to introduce the growing field of adversarial attacks. </span>
                        			<br>
                        			<br>
                        			<span><a class="link" href="https://ahprojects.com/hyperface/" target="_blank">Read More</a></span>
                    			</div>
								</div>
							</div>
						</div>
					</td>  
			    </tr>
			    <tr>
					<td href='#project1' class="reply">
            			<span class="cover">
            				<div class="popup-container-images-2">
                   				<span class="col1">06.2018</span>
                    			<span class="col2">Obvious Collective</span>
                			<div class="popup-detail-image-2">
                    			<img class="image-hover"src="imagens/obvious.png">
               				 </div>
            				</div>
            			</span>
						<div class='target' style='display:none'>
							<div class="content-columns">
                    			<div class="col3">
                        			<img class="image"src="imagens/obvious.png">
                        			<br>
                        			<span class="bodytext"> The artworks of the Obvious Collective (nomen est omen), a collaborative project that creates paintings using AI, provide visual evidence of these limitations. The style of their portraiture is highly normalised and aesthetically predictable.36 It would therefore be more accurate to term AI art as statistical art.</span>
                        			<br>
                        			<br>
                        			<span><a class="link" href="https://obvious-art.com/page-about-obvious/" target="_blank">Read More</a></span>
                    			</div>
								</div>
							</div>
						</div>
					</td>  
			    </tr>
			    <tr>
					<td href='#project1' class="reply">
            			<span class="cover">
            				<div class="popup-container-images-2">
                   				<span class="col1">(-).2019</span>
                    			<span class="col2">IBM's Diversity in Faces</span>
                			<div class="popup-detail-image-2">
                    			<img class="image-hover"src="imagens/ibm.png">
               				 </div>
            				</div>
            			</span>
						<div class='target' style='display:none'>
							<div class="content-columns">
                    			<div class="col3">
                        			<img class="image"src="imagens/ibm.png">
                        			<br>
                        			<span class="bodytext">Diversity in Faces set still relies on a binary classification for gender: people can only be labelled male or female. Achieving parity amongst different categories is not the same as achieving diversity or fairness, and IBM’s data construction and analysis perpetuates a harmful set of classifications within a narrow worldview.</span>
                        			<br>
                        			<br>
                        			<span><a class="link" href="https://excavating.ai/" target="_blank">Read More</a></span>
                    			</div>
								</div>
							</div>
						</div>
					</td>  
			    </tr>
			    <tr>
					<td href='#project1' class="reply">
            			<span class="cover">
            				<div class="popup-container-images-2">
                   				<span class="col1">(-).2019</span>
                    			<span class="col2">UTK’s Data Faces</span>
                			<div class="popup-detail-image-2">
                    			<img class="image-hover"src="imagens/utk.png">
               				 </div>
            				</div>
            			</span>
						<div class='target' style='display:none'>
							<div class="content-columns">
                    			<div class="col3">
                        			<img class="image"src="imagens/utk.png">
                        			<br>
                        			<span class="bodytext">UTKFace dataset (produced by a group at the University of Tennessee at Knoxville) consists of over 20,000 images of faces with annotations for age, gender, and race.<br>
									The annotations for each image include an estimated age for each person, expressed in years from zero to 116. Gender is a binary choice: either zero for male or one for female. Second, race is categorized from zero to four, and places people in one of five classes: White, Black, Asian, Indian, or “Others.</span>
                        			<br>
                        			<br>
                        			<span><a class="link" href="https://excavating.ai/" target="_blank">Read More</a></span>
                    			</div>
								</div>
							</div>
						</div>
					</td>  
			    </tr>
			    <tr>
					<td href='#project1' class="reply">
            			<span class="cover">
            				<div class="popup-container-images-2">
                   				<span class="col1">01.2019</span>
                    			<span class="col2">Amazon's Rekognition</span>
                			<div class="popup-detail-image-2">
                    			<img class="image-hover"src="imagens/rekognition.png">
               				 </div>
            				</div>
            			</span>
						<div class='target' style='display:none'>
							<div class="content-columns">
                    			<div class="col3">
                        			<img class="image"src="imagens/rekognition.png">
                        			<br>
                        			<span class="bodytext">Rekognition, Amazon Web Services’ (AWS) object detection API, fails to reliably determine the sex of female and darker-skinned faces in specific scenarios.</span>
                        			<br>
                        			<br>
                        			<span><a class="link" href="https://venturebeat.com/ai/amazon-rekognition-bias-mit/" target="_blank">Read More</a></span>
                    			</div>
								</div>
							</div>
						</div>
					</td>  
			    </tr>
			    <tr>
					<td href='#project1' class="reply">
            			<span class="cover">
            				<div class="popup-container-images-2">
                   				<span class="col1">(-).2020</span>
                    			<span class="col2">The Nooscope Manifested</span>
                			<div class="popup-detail-image-2">
                    			<img class="image-hover"src="imagens/nooscope.png">
               				 </div>
            				</div>
            			</span>
						<div class='target' style='display:none'>
							<div class="content-columns">
                    			<div class="col3">
                        			<img class="image"src="imagens/nooscope.png">
                        			<br>
                        			<span class="bodytext">The Nooscope is a cartography of the limits of artificial intelligence, intended as a provocation to both computer science and the humanities. Any map is a partial perspective, a way to provoke debate. Similarly, this map is a manifesto — of AI dissidents. Its main purpose is to challenge the mystifications of artificial intelligence.</span>
                        			<br>
                        			<br>
                        			<span><a class="link" href="https://www.designweek.co.uk/issues/13-19-january-2020/unconscious-bias-ai-voice-assistants/" target="_blank">Read More</a></span>
                    			</div>
								</div>
							</div>
						</div>
					</td>  
			    </tr>
			    <tr>
					<td href='#project1' class="reply">
            			<span class="cover">
            				<div class="popup-container-images-2">
                   				<span class="col1">01.2020</span>
                    			<span class="col2">Amazon's Eco</span>
                			<div class="popup-detail-image-2">
                    			<img class="image-hover"src="imagens/echo.png">
               				 </div>
            				</div>
            			</span>
						<div class='target' style='display:none'>
							<div class="content-columns">
                    			<div class="col3">
                        			<img class="image"src="imagens/echo.png">
                        			<br>
                        			<span class="bodytext">Voice-assistants are becoming a part of our everyday lives, but they don’t understand everyone’s voices equally. We explore how the industry is addressing that inequality.</span>
                        			<br>
                        			<br>
                        			<span><a class="link" href="https://www.designweek.co.uk/issues/13-19-january-2020/unconscious-bias-ai-voice-assistants/" target="_blank">Read More</a></span>
                    			</div>
								</div>
							</div>
						</div>
					</td>  
			    </tr>
			    <tr>
					<td href='#project1' class="reply">
            			<span class="cover">
            				<div class="popup-container-images-2">
                   				<span class="col1">09.2021</span>
                    			<span class="col2">Google Translate</span>
                			<div class="popup-detail-image-2">
                    			<img class="image-hover"src="imagens/google.png">
               				 </div>
            				</div>
            			</span>
						<div class='target' style='display:none'>
							<div class="content-columns">
                    			<div class="col3">
                        			<img class="image"src="imagens/google.png">
                        			<br>
                        			<span class="bodytext">When Google Translate started using NMT, people noticed a bias when translating from non-gendered to gendered languages.</span>
                        			<br>
                        			<br>
                        			<span><a class="link" href="https://algorithmwatch.org/en/google-translate-gender-bias/" target="_blank">Read More</a></span>
                    			</div>
								</div>
							</div>
						</div>
					</td>  
			    </tr>
			</tbody>
		</table>
		</div>
	</main>

	<script type="text/javascript" src="javascript.js"></script>
</body>
</html>